{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --quiet langchain\n",
    "!pip install --upgrade --quiet huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3cabd59aa14800b44a93751be99a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 토큰 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트 템플릿 생성\n",
    "question=\"당신은 농업 전문가입니다. 토마토는 과일인가요? 한글로 알려주세요. \"\n",
    "template = \"\"\"Question: {question} Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\cowbo\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "\n",
      "\n",
      "1. 토마토는 과일이자 채소로 분류될 수 있습니다.\n",
      "2. 과일은 일반적으로 열매를 가리킵니다.\n",
      "3. 토마토는 열매입니다.\n",
      "4. 그러나, 일반적으로 과일로 인식되는 것들은 당도가 높고 식용시 단백질이나 지방을 함유하는 것들입니다.\n",
      "5. 토마토는 당도가 낮고 식용시 당분과 비타민 C를 함유하는 것입니다.\n",
      "6. 따라서, 토마토는 과일이지만, 일반적으로 과일로 인식되는 것들과는 다른 특성을 가지고 있습니다.\n",
      "\n",
      "따라서, 토마토는 과일이지만, 일반적으로 과일로 인식되는 것들과는 다른 특성을 가지고 있습니다. 따라서, 토마토는 과일이지만, 일반적으로 채소로 분류되는 경우가 많습니다.\n"
     ]
    }
   ],
   "source": [
    "# HuggingFaceHub 객체 생성\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\",  # 모델 저장소 ID를 지정합니다.\n",
    "    max_new_tokens=512,  \n",
    "    temperature=0.01, # 샘플링 온도를 설정합니다. 값이 높을수록 더 다양한 출력을 생성합니다.\n",
    "   # callbacks=[StreamingStdOutCallbackHandler()],  # 콜백을 설정합니다.\n",
    "    streaming=False,  # 스트리밍을 사용합니다.\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# 실행\n",
    "print(llm_chain.run(question=question))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
